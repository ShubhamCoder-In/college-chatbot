{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# college chatbot model train \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since squad couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at C:\\Users\\DeLL\\.cache\\huggingface\\datasets\\squad\\plain_text\\0.0.0\\7b6d24c440a36b6815f21b70d25016731768db1f (last modified on Thu Sep 19 14:10:52 2024).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "squad = load_dataset('squad')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 87599\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 10570\n",
      "    })\n",
      "})\n",
      "{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the structure of the dataset\n",
    "print(squad)\n",
    "\n",
    "# View a sample question-answer pair\n",
    "print(squad['train'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to be used transformer build tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DeLL\\python\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build suaq tokenizer to train nlp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3950e6d8fcc4318b6b6233783fb0561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0028f9e1c50942f8b493492ed603d467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_token_positions(examples):\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\"], examples[\"context\"], \n",
    "        truncation=True, padding='max_length', max_length=512, return_offsets_mapping=True\n",
    "    )\n",
    "    \n",
    "    # Initialize empty lists for start and end positions\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    # Loop through each example\n",
    "    for i, offsets in enumerate(tokenized_examples[\"offset_mapping\"]):\n",
    "        # Get the answer's start and end position in characters\n",
    "        start_char = examples[\"answers\"][i]['answer_start'][0]\n",
    "        end_char = start_char + len(examples[\"answers\"][i]['text'][0])\n",
    "\n",
    "        # Initialize token start and end indices\n",
    "        token_start_index = 0\n",
    "        token_end_index = 0\n",
    "\n",
    "        # Find the token index that corresponds to the character positions\n",
    "        for j, (start, end) in enumerate(offsets):\n",
    "            if start <= start_char < end:\n",
    "                token_start_index = j\n",
    "            if start < end_char <= end:\n",
    "                token_end_index = j\n",
    "                break\n",
    "\n",
    "        start_positions.append(token_start_index)\n",
    "        end_positions.append(token_end_index)\n",
    "\n",
    "    tokenized_examples[\"start_positions\"] = start_positions\n",
    "    tokenized_examples[\"end_positions\"] = end_positions\n",
    "\n",
    "    # Remove the offset mappings, as they are no longer needed\n",
    "    tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    return tokenized_examples\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "tokenized_squad = squad.map(add_token_positions, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import pretrind model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs=2  # Lower the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO INCREACE ACCURACY SET TRAINIG ARGUMRNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",  \n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,  # Mixed precision training\n",
    "    load_best_model_at_end=True  # Required for EarlyStoppingCallback\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data in small size to get accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a5f998c35b4ed4877832b590914f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6154cc6a9e1949138ff0a342c1ddb8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.021636486053467, 'eval_runtime': 14.1352, 'eval_samples_per_second': 2.122, 'eval_steps_per_second': 0.283, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d38a14c46c34803ab22ed841f4c8201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.923923969268799, 'eval_runtime': 14.8645, 'eval_samples_per_second': 2.018, 'eval_steps_per_second': 0.269, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babc18319eac47cba21aa12829fc665c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.89273738861084, 'eval_runtime': 14.4158, 'eval_samples_per_second': 2.081, 'eval_steps_per_second': 0.277, 'epoch': 3.0}\n",
      "{'train_runtime': 509.9568, 'train_samples_per_second': 0.588, 'train_steps_per_second': 0.076, 'train_loss': 4.611846141326121, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=39, training_loss=4.611846141326121, metrics={'train_runtime': 509.9568, 'train_samples_per_second': 0.588, 'train_steps_per_second': 0.076, 'total_flos': 39195930009600.0, 'train_loss': 4.611846141326121, 'epoch': 3.0})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a small fraction of the dataset (e.g., 10%)\n",
    "small_train_dataset = tokenized_squad['train'].shuffle(seed=42).select(range(100))\n",
    "small_eval_dataset = tokenized_squad['validation'].shuffle(seed=42).select(range(30))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,  # Subset for faster training\n",
    "    eval_dataset=small_eval_dataset,    # Smaller validation set\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    {'eval_loss': 5.021636486053467, 'eval_runtime': 14.1352, 'eval_samples_per_second': 2.122, 'eval_steps_per_second': 0.283, 'epoch': 1.0}\n",
    "    {'eval_loss': 4.923923969268799, 'eval_runtime': 14.8645, 'eval_samples_per_second': 2.018, 'eval_steps_per_second': 0.269, 'epoch': 2.0}\n",
    "    {'eval_loss': 4.89273738861084, 'eval_runtime': 14.4158, 'eval_samples_per_second': 2.081, 'eval_steps_per_second': 0.277, 'epoch': 3.0}\n",
    "    {'train_runtime': 509.9568, 'train_samples_per_second': 0.588, 'train_steps_per_second': 0.076, 'train_loss': 4.611846141326121, 'epoch': 3.0}\n",
    "    TrainOutput(global_step=39, training_loss=4.611846141326121, metrics={'train_runtime': 509.9568, 'train_samples_per_second': 0.588, 'train_steps_per_second': 0.076, 'total_flos': 39195930009600.0, 'train_loss': 4.611846141326121, 'epoch': 3.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model evaluation to find score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998a7a8ba0ba49b59c0fbe5640b68e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 4.89273738861084, 'eval_runtime': 13.1403, 'eval_samples_per_second': 2.283, 'eval_steps_per_second': 0.304, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance on the validation set\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Evaluation results: {'eval_loss': 4.89273738861084, 'eval_runtime': 13.1403, 'eval_samples_per_second': 2.283, 'eval_steps_per_second': 0.304, 'epoch': 3.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save dataset model to development "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "trainer.save_model(\"./trained_chatbot_model\")\n",
    "\n",
    "# Save the tokenizer if needed\n",
    "tokenizer.save_pretrained(\"./trained_chatbot_model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
